
# Required connection configs for Kafka producer, consumer, and admin
bootstrap.servers=<KAFKA_BOOTSTRAP>:9092
security.protocol=SASL_SSL
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='<CONSUMER_API_KEY>' password='<CONSUMER_API_SECRET>';
sasl.mechanism=PLAIN
# Required for correctness in Apache Kafka clients prior to 2.6
client.dns.lookup=use_all_dns_ips

key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer
specific.avro.reader=true
group.id=customers-management-app
enable.autocommit=false
auto.offset.reset=earliest

# Required connection configs for Confluent Cloud Schema Registry
schema.registry.url=https://<SR_ENDPOINT>
basic.auth.credentials.source=USER_INFO
basic.auth.user.info=<SR_API_KEY>:<SR_API_SECRET>

# Configuration for client side field level encryption
rule.executors._default_.param.access.key.id=<AWS_KEY>
rule.executors._default_.param.secret.access.key=<AWS_SECRET>

# Required since we manually create schemas
use.latest.version=true
auto.register.schemas=false